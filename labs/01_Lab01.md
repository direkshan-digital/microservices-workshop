# Day 1 - Lab 1 : Proof of concept deployment

**Duration**: 20 minutes

In this exercise, you will take the starter files and run the ASP.NET Core application to get familiar with the application, and then prepare it for deployment as a Docker application. You will create a Dockerfile, commit this to the repository, and trigger a Docker image build in Azure DevOps. This will generate the Docker images and push them to the Azure Container Registry.

## Exercise 1: Create and run a Docker application

### Task 1: Review the application

The purpose of this task is to make sure you can run the application successfully before applying changes to run it as a Docker application. This will give you an idea of the application functionality expected when you deploy it to Azure.

   ```text
   TODO: for this task
   update this to use ASP.NET Core application
   change steps to tour the application matching core
   change to remove mongo step, app should be already connected to cosmos
   check all steps, for accuracy, including screenshot updates
   ```

   ```text
   TODO: maybe add this next cosmos check task somewhere?
   ```

1. Open the [Azure Portal](https://portal.azure.com)
2. Login with your lab username and password that was provided via email. Close any welcome dialogs.
3. Select **Resource Groups**
4. Select the **ODL-DV13-SUFFIX-fabmedical** resource group

   ![The Cosmos DB resource is highlighted.](media/select-resource-group.png)

5. Select the **fabmedical-SUFFIX** Azure Cosmos DB account

   ![The Cosmos DB resource is highlighted.](media/azure-cosmosdb-select.png)

6. In the blade menu, select **Data Explorer**, notice it contains two collections that have been pre-populated with data.

   ![A screenshot of the Azure Portal showing Cosmos DB collections.](media/Ex2-Task5.8.png)

7. Open the Azure Cloud Shell by select the cloud shell icon at the top of the page.

   ![The Cosmos DB resource is highlighted.](media/cloud-shell-open.png)

8. Select `PowerShell`.

   ![The Cosmos DB resource is highlighted.](media/cloud-shell-powershell.png)

9. Select **Show advanced settings**.
10. For the storage account, type **MyShellSUFFIX**, be sure to replace SUFFIX.
11. For the file share, type **MyShellSUFFIX**, be sure to replace SUFFIX.
12. Select **Create storage**.

   ![The Cosmos DB resource is highlighted.](media/cloud-shell-create.png "Select the app service")

13. Run the following commands to get the IP address of your build agent VM, be sure to replace the SUFFIX.

   ```bash
   az vm show -d -g ODL-DV13-SUFFIX-fabmedical -n fabmedical-SUFFIX --query publicIps -o tsv
   ```

   > **NOTE** If you don't get an IP back, make sure the VM is started.

14. In the new cloud shell, run the following commands to connect to your build agent VM, be sure to replace the IP, enter **yes**, then press **ENTER** when prompted about the key fingerprint.  Enter the same password as your lab user.

   ```bash
   ssh adminfabmedical@<IP>
   ```

   ![SSH Login.](media/ssh-login.png "Login to the build agent VM")

15. Start the mongo db container image:

   ```bash
   sudo docker network create fabmedical
   sudo docker container run --name mongo --net fabmedical -p 27017:27017 -d mongo
   ```

16. Load the database

   ```bash
   cd content-init
   npm install
   node server.js
   #dotnet run
   ```

17. Navigate to the content-api directory and run the API.

   ```bash
   cd ../content-api
   npm install
   node server.js &
   #dotnet run
   ```

   ![In this screenshot, nodejs ./server.js & has been typed and run at the command prompt, which starts the API as a background process.](media/image47.png)

18. Test the API using curl. You will request the speaker's content, and this will return a JSON result.

   ```bash
   curl http://localhost:3001/speakers
   ```

   ![In this screenshot, made a curl request to view speakers.](media/image47_1.png)

19. Navigate to the web application directory and run the application.

   ```bash
   cd ../content-web
   node server.js &
   #dotnet run
   ```

   ![In this screenshot, after navigating to the web application directory, nodejs ./server.js & has been typed and run at the command prompt, which runs the application as a background process as well.](media/image48.png)

20. From the cloud shell in the build machine edit the app.js file using vim. Notice the IP address has been updated to the build machine IP for you.

   ```bash
   vim app.js
   ```

21. Type **q!** to exit the editor
22. Now run the content-web application in the background.

    ```bash
    node app.js &
    #dotnet run
    ```

23. Press **ENTER** again to get a command prompt for the next step.
24. Test the web application using curl. You will see HTML output returned without errors.

    ```bash
    curl http://localhost:3000
    ```

25. If you received a JSON response to the /speakers content request and an HTML response from the web application, your environment is working as expected.

26. Leave the application running in the console, for the next task.

27. Test the web application from a browser. Navigate to the web application using your build agent IP address you record from above at port 3000.

   ```text
   http://[BUILDAGENTIP]:3000

   EXAMPLE: http://13.68.113.176:3000
   ```

27. Select the Speakers and Sessions links in the header. You will see the pages display the HTML version of the JSON content you curled previously.

28. Once you have verified the application is accessible through a browser, go to your cloud shell window and stop the running node processes.

   ```bash
   TODO: how to stop the dotnetcore apps???
   killall nodejs
   killall node
   ```

> TODO: Task 3 - I put this in the repo already to be automated and skipped...should you remove this or is there value?

### Task 3: Create a Dockerfile

In this task, you will create a new Dockerfile that will be used to run the API application as a containerized application.

> **Note**: You will be working in a Linux VM without friendly editor tools. You must follow the steps very carefully to work with Vim for a few editing exercises if you are not already familiar with Vim.

1. From cloud shell, navigate to the content-api folder. List the files in the folder with this command. The output should look like the screenshot below.

   ```bash
   cd ../content-api
   ll
   ```

   ![In this screenshot of the console window, ll has been typed and run at the command prompt. The files in the folder are listed in the window. At this time, we are unable to capture all of the information in the window. Future versions of this course should address this.](media/image55.png)

2. Create a new file named "Dockerfile" and note the casing in the name. Use the
   following Vim command to create a new file. The cloud shell window should
   look as shown in the following screenshot.

   ```bash
   vi Dockerfile
   ```

   ![This is a screenshot of a new file named Dockerfile in the console window.](media/image56.png)

3. Select "i" on your keyboard. You will see the bottom of the window showing INSERT mode.

   ![-- INSERT -- appears at the bottom of the Dockerfile window.](media/image57.png)

4. Type the following into the file. These statements produce a Dockerfile that describes the following:

   ```text
   TODO: update all of this with the docker base image for dotnetcore sample
   and all the other changes to do this work, go get the aspnetcore sample in its complete form
   ```

   - The base stage includes environment setup which we expect to change very rarely, if at all.

     - Creates a new Docker image from the base image node:alpine. This base image has node.js on it and is optimized for small size.

     - Add `curl` to the base image to support Docker health checks.

     - Creates a directory on the image where the application files can be copied.

     - Exposes application port 3001 to the container environment so that the application can be reached at port 3001.

   - The build stage contains all the tools and intermediate files needed to create the application.

     - Creates a new Docker image from node:argon.

     - Creates a directory on the image where the application files can be copied.

     - Copies package.json to the working directory.

     - Runs npm install to initialize the node application environment.

     - Copies the source files for the application over to the image.

   - The final stage combines the base image with the build output from the build stage.

     - Sets the working directory to the application file location.

     - Copies the app files from the build stage.

     - Indicates the command to start the node application when the container is run.

   > **Note**: Type the following into the editor, as you may have errors with copying and pasting:

   ```Dockerfile
   FROM node:alpine AS base
   RUN apk -U add curl
   WORKDIR /usr/src/app
   EXPOSE 3001

   FROM node:argon AS build
   WORKDIR /usr/src/app

   # Install app dependencies
   COPY package.json /usr/src/app/
   RUN npm install

   # Bundle app source
   COPY . /usr/src/app

   FROM base AS final
   WORKDIR /usr/src/app
   COPY --from=build /usr/src/app .
   CMD [ "npm", "start" ]
   ```

5. When you are finished typing, hit the Esc key and type ":wq" and hit the Enter key to save the changes and close the file.

   ```bash
   <Esc>
   :wq
   <Enter>
   ```

6. List the contents of the folder again to verify that the new Dockerfile has been created.

   ```bash
   ll
   ```

   ![In this screenshot of the console window, ll has been typed and run at the command prompt. The Dockerfile file is highlighted at the top of list.](media/image58.png)

7. Verify the file contents to ensure it was saved as expected. Type the following command to see the output of the Dockerfile in the command window.

   ```bash
   cat Dockerfile
   ```

### Task 4: Build images and push to Azure Container Registry with a DevOps pipeline

In this task, you will review the YAML definition for the pipeline that builds your Docker image and pushes it to your ACR instance.

1. Open a browser window to [Azure DevOps](https://dev.azure.com)
2. Login using your lab username and password
3. If prompted, select **Continue**
4. Select the **fabmedical** project

   ![The fabmedical project is displayed.](media/devops-project.png)

5. Select the **Repos** link, then select the **content-api** repo from the dropdown

   ![The click path is highlighted.](media/devops-select-repo.png)

6. Select the **azure-pipelines.yml** file

   ![A screenshot of the content-web repository with an arrow pointed at the Set up Build button.](media/azure-pipelines-yaml.png)

7. Review the build definition, if the **[SHORT_SUFFIX]** has not been replaced, select **Edit**, then replace it with your SUFFIX. Likely this has been done for you. Select **Commit** then select **Commit** again.

   ![Short suffix is highlighted.](media/pipeline-short-suffix.png)

8. Navigate back to the repo by selecting the folder icon

   ![Folder icon is highlighted.](media/navigate-up.png)

9. Select **Set up build**
  
   ![A screenshot of the content-web repository with an arrow pointed at the Set up Build button.](media/hol-2019-10-01_19-50-16.png)

> TODO: Azure DevOps automatically detects the pipeline YAML files (???? EXPLAIN THIS???).

FOR EXAMPLE: 

   ```yaml
   name: 0.1.$(Rev:r)

   trigger:
     - master

   resources:
     - repo: self

   variables:
     dockerRegistryServiceConnection: "Fabmedical ACR"
     imageRepository: "content-web"
     containerRegistry: "$(containerRegistryName).azurecr.io"
     containerRegistryName: "fabmedical[SHORT_SUFFIX]"
     dockerfilePath: "$(Build.SourcesDirectory)/Dockerfile"
     tag: "$(Build.BuildNumber)"
     vmImageName: "ubuntu-latest"

   stages:
     - stage: Build
       displayName: Build and Push
       jobs:
         - job: Docker
           displayName: Build and Push Docker Image
           pool:
             vmImage: $(vmImageName)
           steps:
             - checkout: self
               fetchDepth: 1

             - task: Docker@2
               displayName: Build and push an image to container registry
               inputs:
                 command: buildAndPush
                 repository: $(imageRepository)
                 dockerfile: $(dockerfilePath)
                 containerRegistry: $(dockerRegistryServiceConnection)
                 tags: |
                   $(tag)
                   latest
   ```

9. Select `Run` to run the content-api pipeline.

   ![A screenshot of the "Review your pipeline YAML" page.  An arrow points at the Run button.](media/hol-2019-10-02_07-33-16.png)

10. Azure DevOps will queue your first build and execute the pipeline when an
   agent becomes available.

   ![A screenshot of Azure DevOps Pipeline with a queued job.](media/hol-2019-10-02_07-39-24.png)

11. The build should take about five minutes to complete. Select the **Build and Push Docker Image** to watch the progress.

   ![A screenshot of Azure DevOps Pipeline with a completed job.](media/hol-2019-10-02_08-28-49.png)

12. The build may fail due to an authorization error related to the Docker Registry Service connection. If this is the case, then select **View** and then **Authorize Resources** and run the build again.

   ![A screenshot showing an authorization failure error. An arrow points to the Authorize Resources button.](media/hol-2019-10-02_07-30-37.png)

13. Select **Permit**, then select **Permit** again

   ![Permit is highlighted.](media/pipeline-permit.png)

14. From Azure DevOps, navigate to **Repos**

15. Select the `content-web` repository from the dropdown. This repository also includes the `azure-pipelines.yaml`.

16. Select **Set up Build**

17. In the "Review your pipeline YAML" step, edit the `containerRegistryName` value to replace `[SHORT_SUFFIX]` with your SUFFIX so that it matches your container registry's name.

   ![A screenshot of the "Review your pipeline YAML" step, with the containerRegistryName property highlighted.](media/hol-2019-10-18_06-32-34.png)

17. When you are finished editing, select **Save and run**.

18. In the dialog, select **Save and run**. This will start the build process.

19. Select the **Build and Push Docker Image** job, again, this will display the activities of the build agent.

### Task 5: List images in the Azure Container Registry

In this task you will verify the images are present after the Azure DevOps build pipeline completes.

1. Switch to the Azure Portal
2. Navigate to your **ODL-DV13-SUFFIX-fabmedical** resource group
3. Select the **fabmedicalSUFFIX** Azure Container Registry (ACR)
4. Under **Services**, select **Repositories**. You will now see two, one for each image.

   ![In this screenshot, content-api and content-web each appear on their own lines below Repositories.](media/image68.png)

5. Select **content-api**, you will see the `latest` tag is assigned as well as a build number tag.

   ![In this screenshot, content-api is selected under Repositories, and the Tags blade appears on the right.](media/image69.png)

## Reference Links

- Azure Cloud Shell
- Docker
- Azure DevOps
- Azure Container Registry (ACR)
- YAML